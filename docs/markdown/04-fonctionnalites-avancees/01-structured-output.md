<!-- .slide: class="transition" -->

# Structured Output

##==##

<!-- .slide -->

# Structured Output : Vue d'ensemble

## Pourquoi structurer les √©changes ?

Les LLMs g√©n√®rent naturellement du texte non structur√©. Pour les int√©grer dans des syst√®mes logiciels, nous avons besoin de **garanties** sur le format des entr√©es et sorties.

<br>

### 3 M√©canismes Cl√©s :

1. **Input Schema** üì• : Valide ce qui entre dans l'agent
2. **Output Schema** üì§ : Force le format de ce qui sort (JSON)
3. **Output Key** üîë : Sauvegarde automatiquement le r√©sultat dans le state

Sans structure, le parsing des r√©ponses est fragile et sujet aux erreurs. Ces outils rendent les agents d√©terministes dans leur format.
<!-- .element: class="admonition tip" -->

##==##

<!-- .slide: class="with-code max-height" -->

# Input Schema

## Valider les entr√©es utilisateur

D√©finit la structure attendue pour les messages envoy√©s √† l'agent.

```python
from google.adk.agents import LlmAgent
from pydantic import BaseModel, Field

# D√©finition du sch√©ma d'entr√©e
class UserQuery(BaseModel):
    city: str = Field(description="La ville cible")
    days: int = Field(description="Dur√©e du s√©jour", ge=1)

# Configuration de l'agent
travel_agent = LlmAgent(
    name="TravelGuide",
    model="gemini-2.5-flash",
    input_schema=UserQuery,  # Validation automatique
    system_instruction="Cr√©e un itin√©raire de voyage."
)
```

En utilisant Pydantic pour la validation, si l'entr√©e ne correspond pas au sch√©ma, une erreur est lev√©e avant m√™me d'appeler le mod√®le.

<!-- .element: class="admonition note" -->

##==##

<!-- .slide: class="with-code max-height" -->

# Output Schema

## Forcer une r√©ponse structur√©e (JSON)

Garantit que l'agent r√©pondra toujours avec un objet JSON valide conforme √† votre mod√®le.

```python
class TripPlan(BaseModel):
    destination: str
    activities: list[str]
    estimated_cost: float

planner = LlmAgent(
    name="Planner",
    model="gemini-2.0-flash",
    output_schema=TripPlan, # Force le JSON strict
    system_instruction="G√©n√®re un plan de voyage structur√©."
)

# Utilisation
response = await planner.run_async("Paris pour 3 jours")
# response.text sera un JSON valide :
# {"destination": "Paris", "activities": [...], "estimated_cost": 500.0}
```

Indispensable pour que d'autres syst√®mes (API, Frontend, Base de donn√©es) puissent consommer la r√©ponse de l'agent sans parsing complexe.

<!-- .element: class="admonition tip" -->

##==##

<!-- .slide: class="with-code" -->

# Output Key

## Partage de donn√©es multi-agents

Sauvegarde automatiquement la r√©ponse dans le `SessionState` pour les agents suivants.

```python
researcher = LlmAgent(
    name="Researcher",
    # ...
    output_key="research_data"  # Sauvegarde dans state["research_data"]
)
writer = LlmAgent(
    name="Writer",
    # ...
    # Pas besoin de passer explicitement les donn√©es,
    # le writer a acc√®s au state global
    system_instruction="Utilise les donn√©es de recherche pour r√©diger un article: {research_data}."
)
# √âvite d'avoir √† g√©rer manuellement le flux de donn√©es dans le code d'orchestration.
sequential_agent = SequentialAgent(
    name="ResearchAndWrite",
    agents=[researcher, writer]
)
```

Dans un SequentialAgent, c'est le moyen le plus propre de passer le "baton" de donn√©es d'un agent √† l'autre.

<!-- .element: class="admonition tip" -->
